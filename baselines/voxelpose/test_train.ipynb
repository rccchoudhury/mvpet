{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/rchoudhu/research/voxelpose-pytorch/lib\")\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "import argparse\n",
    "import pprint\n",
    "import logging\n",
    "import json\n",
    "import time\n",
    "%matplotlib agg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#import _init_paths\n",
    "from core.config import config\n",
    "from core.config import update_config\n",
    "from core.function import train_3d, validate_3d\n",
    "from utils.utils import create_logger\n",
    "from utils.utils import save_checkpoint, load_checkpoint, load_model_state\n",
    "from utils.utils import load_backbone_panoptic\n",
    "from utils.vis import save_debug_3d_images\n",
    "import dataset\n",
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model):\n",
    "    lr = config.TRAIN.LR\n",
    "    if model.module.backbone is not None:\n",
    "        for params in model.module.backbone.parameters():\n",
    "            params.requires_grad = False   # If you want to train the whole model jointly, set it to be True.\n",
    "    for params in model.module.root_net.parameters():\n",
    "        params.requires_grad = True\n",
    "    for params in model.module.pose_net.parameters():\n",
    "        params.requires_grad = True\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.module.parameters()), lr=lr)\n",
    "    # optimizer = optim.Adam(model.module.parameters(), lr=lr)\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating /home/rchoudhu/research/voxelpose-pytorch/output/panoptic/multi_person_posenet_50/prn64_cpn80x80x20_960x512_cam3\n",
      "=> creating /home/rchoudhu/research/voxelpose-pytorch/log/panoptic/multi_person_posenet_50/prn64_cpn80x80x20_960x512_cam32022-02-08-06-40\n",
      "=> Loading data ..\n"
     ]
    }
   ],
   "source": [
    "cfg = \"configs/panoptic/resnet50/prn64_cpn80x80x20_960x512_cam3.yaml\"\n",
    "update_config(cfg)\n",
    "logger, final_output_dir, tb_log_dir = create_logger(config, cfg, 'train')\n",
    "\n",
    "gpus = [int(i) for i in config.GPUS.split(',')]\n",
    "print('=> Loading data ..')\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = eval('dataset.' + config.DATASET.TRAIN_DATASET)(\n",
    "        config, config.DATASET.TRAIN_SUBSET, True,\n",
    "        transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.TRAIN.BATCH_SIZE * len(gpus),\n",
    "    shuffle=config.TRAIN.SHUFFLE,\n",
    "    num_workers=config.WORKERS,\n",
    "    pin_memory=True)\n",
    "\n",
    "test_dataset = eval('dataset.' + config.DATASET.TEST_DATASET)(\n",
    "    config, config.DATASET.TEST_SUBSET, False,\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config.TEST.BATCH_SIZE * len(gpus),\n",
    "    shuffle=False,\n",
    "    num_workers=config.WORKERS,\n",
    "    pin_memory=True)\n",
    "\n",
    "cudnn.benchmark = config.CUDNN.BENCHMARK\n",
    "torch.backends.cudnn.deterministic = config.CUDNN.DETERMINISTIC\n",
    "torch.backends.cudnn.enabled = config.CUDNN.ENABLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Constructing models ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> init weights from normal distribution\n",
      "Took 0.231 to finish initing weights.\n",
      "Setting data parallel with gpus: [5]\n",
      "Took 6.105 to set up data parallel\n"
     ]
    }
   ],
   "source": [
    "print('=> Constructing models ..')\n",
    "model = eval('models.' + config.MODEL + '.get_multi_person_pose_net')(\n",
    "    config, is_train=True)\n",
    "\n",
    "logger.info(\"Setting data parallel with gpus: \" + str(gpus))\n",
    "gpus=[0]\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    model = torch.nn.DataParallel(model, device_ids=gpus).cuda()\n",
    "logger.info(\"Took %.3f to set up data parallel\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting optimizer ... \n",
      "loading panoptic backbone\n",
      "Loading panoptic backbone...\n",
      "Finished loading panoptic backbone in 0.003\n",
      "load backbone statedict from /home/rchoudhu/research/voxelpose-pytorch/models/pose_resnet50_panoptic.pth.tar\n",
      "Took 0.203 to load panoptic backbone.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reiniting final layer filters: final_layer.weight\n",
      "Reiniting final layer biases: final_layer.bias\n",
      "=> no checkpoint found at /home/rchoudhu/research/voxelpose-pytorch/output/panoptic/multi_person_posenet_50/prn64_cpn80x80x20_960x512_cam3/checkpoint.pth.tar\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Getting optimizer ... \")\n",
    "model, optimizer = get_optimizer(model)\n",
    "\n",
    "start_epoch = config.TRAIN.BEGIN_EPOCH\n",
    "end_epoch = config.TRAIN.END_EPOCH\n",
    "\n",
    "best_precision = 0\n",
    "if config.NETWORK.PRETRAINED_BACKBONE:\n",
    "    logger.info(\"loading panoptic backbone\")\n",
    "    panoptic_load_start_time = time.time()\n",
    "    model = load_backbone_panoptic(model, config.NETWORK.PRETRAINED_BACKBONE)\n",
    "    logger.info(\"Took %.3f to load panoptic backbone.\" % (time.time() - panoptic_load_start_time))\n",
    "if config.TRAIN.RESUME:\n",
    "    start_epoch, model, optimizer, best_precision = load_checkpoint(model, optimizer, final_output_dir)\n",
    "\n",
    "writer_dict = {\n",
    "    'writer': SummaryWriter(log_dir=tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Training...\n",
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rchoudhu/.conda/envs/voxelpose_test/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811803361/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/rchoudhu/research/voxelpose-pytorch/lib/core/proposal.py:19: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  indices_x = (indices // (shape[1] * shape[2])).reshape(batch_size, num_people, -1)\n",
      "/home/rchoudhu/research/voxelpose-pytorch/lib/core/proposal.py:20: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  indices_y = ((indices % (shape[1] * shape[2])) // shape[2]).reshape(batch_size, num_people, -1)\n",
      "Epoch: [0][0/23109]\tTime: 10.941s (10.941s)\tSpeed: 0.3 samples/s\tData: 1.856s (1.856s)\tLoss: 272.919037 (272.919037)\tLoss_2d: 0.0004557 (0.0004557)\tLoss_3d: 0.0013124 (0.0013124)\tLoss_cord: 272.917267 (272.917267)\tMemory 198185984.0\n",
      "Epoch: [0][100/23109]\tTime: 0.300s (0.352s)\tSpeed: 10.0 samples/s\tData: 0.001s (0.032s)\tLoss: 106.063713 (126.420884)\tLoss_2d: 0.0002445 (0.0002202)\tLoss_3d: 0.0007590 (0.0005695)\tLoss_cord: 106.062706 (126.420095)\tMemory 252411904.0\n",
      "Epoch: [0][200/23109]\tTime: 0.168s (0.285s)\tSpeed: 17.8 samples/s\tData: 0.001s (0.020s)\tLoss: 93.238541 (106.599715)\tLoss_2d: 0.0001847 (0.0002174)\tLoss_3d: 0.0000739 (0.0003896)\tLoss_cord: 93.238281 (106.599108)\tMemory 252411904.0\n",
      "Epoch: [0][300/23109]\tTime: 0.174s (0.266s)\tSpeed: 17.2 samples/s\tData: 0.000s (0.016s)\tLoss: 67.293480 (97.374496)\tLoss_2d: 0.0001523 (0.0002146)\tLoss_3d: 0.0000247 (0.0002983)\tLoss_cord: 67.293304 (97.373983)\tMemory 252411904.0\n",
      "Epoch: [0][400/23109]\tTime: 0.219s (0.251s)\tSpeed: 13.7 samples/s\tData: 0.001s (0.014s)\tLoss: 73.576180 (92.693897)\tLoss_2d: 0.0001639 (0.0002145)\tLoss_3d: 0.0000407 (0.0002527)\tLoss_cord: 73.575974 (92.693430)\tMemory 252411904.0\n",
      "Epoch: [0][500/23109]\tTime: 0.267s (0.241s)\tSpeed: 11.2 samples/s\tData: 0.000s (0.013s)\tLoss: 72.599854 (88.753385)\tLoss_2d: 0.0003147 (0.0002175)\tLoss_3d: 0.0000664 (0.0002214)\tLoss_cord: 72.599472 (88.752946)\tMemory 252411904.0\n",
      "Epoch: [0][600/23109]\tTime: 0.216s (0.240s)\tSpeed: 13.9 samples/s\tData: 0.001s (0.013s)\tLoss: 76.997055 (85.042040)\tLoss_2d: 0.0002433 (0.0002209)\tLoss_3d: 0.0000431 (0.0002000)\tLoss_cord: 76.996765 (85.041619)\tMemory 252411904.0\n",
      "Epoch: [0][700/23109]\tTime: 0.264s (0.239s)\tSpeed: 11.4 samples/s\tData: 0.000s (0.012s)\tLoss: 65.344444 (81.016828)\tLoss_2d: 0.0007475 (0.0002239)\tLoss_3d: 0.0000988 (0.0001837)\tLoss_cord: 65.343597 (81.016420)\tMemory 252411904.0\n",
      "Epoch: [0][800/23109]\tTime: 0.206s (0.234s)\tSpeed: 14.5 samples/s\tData: 0.014s (0.012s)\tLoss: 35.695076 (76.994118)\tLoss_2d: 0.0001776 (0.0002212)\tLoss_3d: 0.0000386 (0.0001688)\tLoss_cord: 35.694859 (76.993728)\tMemory 252411904.0\n",
      "Epoch: [0][900/23109]\tTime: 0.130s (0.230s)\tSpeed: 23.1 samples/s\tData: 0.000s (0.011s)\tLoss: 53.423824 (73.379790)\tLoss_2d: 0.0001130 (0.0002197)\tLoss_3d: 0.0000376 (0.0001565)\tLoss_cord: 53.423676 (73.379414)\tMemory 252411904.0\n",
      "Epoch: [0][1000/23109]\tTime: 0.170s (0.226s)\tSpeed: 17.7 samples/s\tData: 0.001s (0.011s)\tLoss: 22.317814 (69.789077)\tLoss_2d: 0.0000905 (0.0002186)\tLoss_3d: 0.0000123 (0.0001450)\tLoss_cord: 22.317711 (69.788713)\tMemory 252411904.0\n",
      "Epoch: [0][1100/23109]\tTime: 0.167s (0.224s)\tSpeed: 17.9 samples/s\tData: 0.001s (0.010s)\tLoss: 18.380148 (66.535355)\tLoss_2d: 0.0000802 (0.0002180)\tLoss_3d: 0.0000093 (0.0001364)\tLoss_cord: 18.380058 (66.535000)\tMemory 252411904.0\n",
      "Epoch: [0][1200/23109]\tTime: 0.218s (0.223s)\tSpeed: 13.8 samples/s\tData: 0.000s (0.010s)\tLoss: 25.179798 (63.369740)\tLoss_2d: 0.0003888 (0.0002211)\tLoss_3d: 0.0000368 (0.0001292)\tLoss_cord: 25.179373 (63.369390)\tMemory 252411904.0\n",
      "Epoch: [0][1300/23109]\tTime: 0.118s (0.222s)\tSpeed: 25.4 samples/s\tData: 0.001s (0.010s)\tLoss: 22.801140 (60.554354)\tLoss_2d: 0.0001822 (0.0002197)\tLoss_3d: 0.0000271 (0.0001222)\tLoss_cord: 22.800930 (60.554012)\tMemory 252411904.0\n",
      "Epoch: [0][1400/23109]\tTime: 0.207s (0.223s)\tSpeed: 14.5 samples/s\tData: 0.001s (0.010s)\tLoss: 16.335054 (57.788712)\tLoss_2d: 0.0001523 (0.0002219)\tLoss_3d: 0.0000128 (0.0001163)\tLoss_cord: 16.334888 (57.788374)\tMemory 252411904.0\n",
      "Epoch: [0][1500/23109]\tTime: 0.124s (0.224s)\tSpeed: 24.2 samples/s\tData: 0.001s (0.010s)\tLoss: 13.350224 (55.465320)\tLoss_2d: 0.0000487 (0.0002209)\tLoss_3d: 0.0000095 (0.0001109)\tLoss_cord: 13.350166 (55.464988)\tMemory 252411904.0\n",
      "Epoch: [0][1600/23109]\tTime: 0.260s (0.225s)\tSpeed: 11.5 samples/s\tData: 0.000s (0.010s)\tLoss: 19.022432 (53.667420)\tLoss_2d: 0.0003038 (0.0002232)\tLoss_3d: 0.0000292 (0.0001070)\tLoss_cord: 19.022099 (53.667089)\tMemory 252411904.0\n",
      "Epoch: [0][1700/23109]\tTime: 0.266s (0.227s)\tSpeed: 11.3 samples/s\tData: 0.001s (0.010s)\tLoss: 14.430983 (51.992280)\tLoss_2d: 0.0001478 (0.0002247)\tLoss_3d: 0.0000091 (0.0001033)\tLoss_cord: 14.430826 (51.991952)\tMemory 252411904.0\n",
      "Epoch: [0][1800/23109]\tTime: 0.107s (0.230s)\tSpeed: 28.1 samples/s\tData: 0.000s (0.010s)\tLoss: 15.576628 (50.362155)\tLoss_2d: 0.0001746 (0.0002264)\tLoss_3d: 0.0000313 (0.0000998)\tLoss_cord: 15.576422 (50.361829)\tMemory 252411904.0\n",
      "Epoch: [0][1900/23109]\tTime: 0.252s (0.229s)\tSpeed: 11.9 samples/s\tData: 0.004s (0.010s)\tLoss: 34.843697 (48.858151)\tLoss_2d: 0.0003583 (0.0002271)\tLoss_3d: 0.0003291 (0.0000967)\tLoss_cord: 34.843010 (48.857827)\tMemory 252411904.0\n",
      "Epoch: [0][2000/23109]\tTime: 0.299s (0.228s)\tSpeed: 10.0 samples/s\tData: 0.000s (0.009s)\tLoss: 17.728455 (47.508412)\tLoss_2d: 0.0004555 (0.0002262)\tLoss_3d: 0.0000476 (0.0000940)\tLoss_cord: 17.727951 (47.508091)\tMemory 252411904.0\n",
      "Epoch: [0][2100/23109]\tTime: 0.135s (0.228s)\tSpeed: 22.1 samples/s\tData: 0.001s (0.009s)\tLoss: 17.303492 (46.173407)\tLoss_2d: 0.0001108 (0.0002266)\tLoss_3d: 0.0000140 (0.0000918)\tLoss_cord: 17.303368 (46.173088)\tMemory 252411904.0\n",
      "Epoch: [0][2200/23109]\tTime: 0.181s (0.227s)\tSpeed: 16.6 samples/s\tData: 0.001s (0.009s)\tLoss: 43.650002 (44.963835)\tLoss_2d: 0.0001156 (0.0002278)\tLoss_3d: 0.0000319 (0.0000894)\tLoss_cord: 43.649853 (44.963518)\tMemory 252411904.0\n",
      "Epoch: [0][2300/23109]\tTime: 0.139s (0.227s)\tSpeed: 21.5 samples/s\tData: 0.000s (0.009s)\tLoss: 13.378952 (43.782517)\tLoss_2d: 0.0001866 (0.0002273)\tLoss_3d: 0.0000087 (0.0000873)\tLoss_cord: 13.378757 (43.782202)\tMemory 252411904.0\n",
      "Epoch: [0][2400/23109]\tTime: 0.297s (0.225s)\tSpeed: 10.1 samples/s\tData: 0.001s (0.009s)\tLoss: 45.920227 (42.749192)\tLoss_2d: 0.0001784 (0.0002268)\tLoss_3d: 0.0001377 (0.0000849)\tLoss_cord: 45.919910 (42.748881)\tMemory 252411904.0\n",
      "Epoch: [0][2500/23109]\tTime: 0.188s (0.224s)\tSpeed: 16.0 samples/s\tData: 0.007s (0.009s)\tLoss: 9.046638 (41.762567)\tLoss_2d: 0.0001168 (0.0002261)\tLoss_3d: 0.0000127 (0.0000826)\tLoss_cord: 9.046508 (41.762258)\tMemory 252411904.0\n",
      "Epoch: [0][2600/23109]\tTime: 0.173s (0.224s)\tSpeed: 17.3 samples/s\tData: 0.001s (0.009s)\tLoss: 12.183149 (40.937652)\tLoss_2d: 0.0002009 (0.0002260)\tLoss_3d: 0.0000106 (0.0000807)\tLoss_cord: 12.182938 (40.937345)\tMemory 252411904.0\n",
      "Epoch: [0][2700/23109]\tTime: 0.170s (0.224s)\tSpeed: 17.7 samples/s\tData: 0.001s (0.009s)\tLoss: 12.668430 (40.020456)\tLoss_2d: 0.0002199 (0.0002266)\tLoss_3d: 0.0000126 (0.0000787)\tLoss_cord: 12.668198 (40.020150)\tMemory 252411904.0\n"
     ]
    }
   ],
   "source": [
    "print('=> Training...')\n",
    "for epoch in range(start_epoch, end_epoch):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "\n",
    "    # lr_scheduler.step()\n",
    "    train_3d(config, model, optimizer, train_loader, epoch, final_output_dir, writer_dict)\n",
    "    precision = validate_3d(config, model, test_loader, final_output_dir)\n",
    "\n",
    "    if precision > best_precision:\n",
    "        best_precision = precision\n",
    "        best_model = True\n",
    "    else:\n",
    "        best_model = False\n",
    "\n",
    "    logger.info('=> saving checkpoint to {} (Best: {})'.format(final_output_dir, best_model))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.module.state_dict(),\n",
    "        'precision': best_precision,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, best_model, final_output_dir)\n",
    "\n",
    "final_model_state_file = os.path.join(final_output_dir,\n",
    "                                        'final_state.pth.tar')\n",
    "logger.info('saving final model state to {}'.format(\n",
    "    final_model_state_file))\n",
    "torch.save(model.module.state_dict(), final_model_state_file)\n",
    "\n",
    "writer_dict['writer'].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3b11fdf824dac3633a9826bd6a6350a128076427a02ff616923448c1271d31e"
  },
  "kernelspec": {
   "display_name": "Python (voxelpose_test)",
   "language": "python",
   "name": "voxelpose_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
